---
title: "TFM"
output: html_document
date: "2023-04-04"
---
# Paquetes
```{r cars, warning=FALSE, message=FALSE}
rm(list=ls(all=TRUE))
library(readxl)
library(dplyr)
library(purrr)
library(gtools)
library(caret)
library(tidyr)
library(knitr)
library(plotly)
library(ggplot2)
library(gbm)
library(timetk)
library(forecast)
library(tictoc)
library(stringr)
library(skimr)
library(tidyverse)
library(xgboost)
library(plyr)
library(lubridate)
library(gdata)
library(prophet)
library(tidymodels)
library(modeltime)
library("zoo")
library(neuralnet)
```

# Introduccion

## Lectura de datos
```{r}
personal_path <- "C:/Users/mp334/OneDrive/Escritorio/TFM/"

data_Ciclo <- read_xlsx(paste0(personal_path,"DatosCicloAprovisionamiento.xlsx"))
data_Venta <- read_xlsx(paste0(personal_path,"Datos.xlsx"), sheet = 'Venta')
data_Calendario <- read_xlsx(paste0(personal_path,"Datos.xlsx"), sheet = 'Calendario')
data_Promo <- read_xlsx(paste0(personal_path,"Datos.xlsx"), sheet = 'Promociones')
data_Stock <- read_xlsx(paste0(personal_path,"Datos.xlsx"), sheet = 'Stock')
data_Precio <- read_xlsx(paste0(personal_path,"DatosPrecioMedio.xlsx"))
```

## Comprovacion datasets
NOTA: En excel ya se han arreglado las fechas para estar en formato Date, ya que nuestros datasets tenian la combinacion fechas en sequencia de numeros, és decir, pasamos de **AAAAMMDD** a **AAAA-MM-DD**.

### Data_Ciclo
```{r}
data_Ciclo <- as.data.frame(data_Ciclo)
summary(data_Ciclo)
head(data_Ciclo)
```

En este dataset tenemos 3 variables:

- **Producto**: Numero identificativo del producto que tenemos.
- **diasEntrePedidos**: Variable entera que nos indica la cantidad de días transcurridos entre dos pedidos consecutivos.
- **diasLeadTime**: Variable entera que representa el tiempo transcurrido desde que se realiza un pedido hasta que se completa y se entrega el producto final.

### Data Venta
```{r}
data_Venta <- as.data.frame(data_Venta)
summary(data_Venta)

# Arreglamos la variable de Fecha
data_Venta$Fecha <- as.Date(data_Venta$Fecha, "%Y-%m-%d")
summary(data_Venta)

# Vamos a ver los productos que no estan en esta hoja
print("Los productos que no tenemos datos de venta son:")
print(setdiff(1:1000, unique(data_Venta$producto)))

# Vemos los primeros productos 
head(data_Venta)
```

En primer lugar, hemos arreglado las Fechas con el formato correcto.
En este dataset tenemos 4 variables:

- **Producto**: Numero identificativo del producto que tenemos.
- **idSecuencia**: Variable entera que tiene la fecha en formato *AAAAMMDD*
- **Fecha**: Transformacion realizada en excel sobre la variable **idSecuencia**, teniendo la fecha en formato correcto para el analisis de resultados.
- **udsVenta**: Variable numerica con la cantidad de productos servidos?

### Data Calendario
```{r}
data_Calendario <- as.data.frame(data_Calendario)
summary(data_Calendario)

# Arreglamos la variable de Fecha
data_Calendario$Fecha <- as.Date(data_Calendario$Fecha, "%Y-%m-%d")
summary(data_Calendario)

# Problemas con el dia 2021-04-04
data_Calendario$Fecha[data_Calendario$idSecuencia == 20210404] <- as.Date("2021-04-04")

# Muestra
head(data_Calendario)
```

Hemos arreglado las Fechas con el formato correcto.
En este dataset tenemos 4 variables:

- **idSecuencia**: Variable entera que tiene la fecha en formato *AAAAMMDD*
- **Fecha**: Transformacion realizada en excel sobre la variable **idSecuencia**, teniendo la fecha en formato correcto para el analisis de resultados.
- **bolOpen**: Variable booleana donde 1 es que la tienda esta abierta y 0 que se encuentra cerrada.
- **bolHoliday**: Variable booleana donde 1 es festivo y 0 es dia laborable.

### Data Promo
```{r}
data_Promo <- as.data.frame(data_Promo)
summary(data_Promo)

# Arreglamos la variable de Fecha
data_Promo$FechaIni <- as.Date(data_Promo$FechaIni, "%Y-%m-%d")
data_Promo$FechaFin <- as.Date(data_Promo$FechaFin, "%Y-%m-%d")
head(data_Promo)
```

Hemos arreglado las Fechas con el formato correcto.
En este dataset tenemos 5 variables:

- **Producto**: Numero identificativo del producto que tenemos.
- **idSecuenciaIni**: Variable entera que tiene la fecha en formato *AAAAMMDD*, donde indica el inicio de la promocion.
- **FechaIni**: Transformacion realizada en excel sobre la variable **idSecuenciaIni**, teniendo la fecha en formato correcto para el analisis de resultados.
- **idSecuenciaFin**: Variable entera que tiene la fecha en formato *AAAAMMDD*, donde indica el inicio de la promocion.
- **FechaFin**: Transformacion realizada en excel sobre la variable **idSecuenciaFin**, teniendo la fecha en formato correcto para el analisis de resultados.

### Data Stock
```{r}
data_Stock <- as.data.frame(data_Stock)
summary(data_Stock)

# Arreglamos la variable de Fecha
data_Stock$Fecha <- as.Date(data_Stock$Fecha, "%Y-%m-%d")
head(data_Stock)
```

Hemos arreglado las Fechas con el formato correcto.
En este dataset tenemos 4 variables:

- **Producto**: Numero identificativo del producto que tenemos.
- **idSecuencia**: Variable entera que tiene la fecha en formato *AAAAMMDD*, donde indica el dia contabilizado el stock.
- **Fecha**: Transformacion realizada en excel sobre la variable **idSecuenciaIni**, teniendo la fecha en formato correcto para el analisis de resultados.
- **udsStock**: Unidades de producto almacenado en la nave?

### Data Precio
```{r}
data_Precio <- as.data.frame(data_Precio)
summary(data_Precio)
```

En este dataset tenemos 2 variables:

- **Producto**: Numero identificativo del producto que tenemos.
- **eurPrecioMedio**: Media de precio de los productos, la usaremos para calcular el coste de almacenamiento.

## Creacion del dataset maestro PER ACI

En esta seccion uniremos todos los datasets en uno, donde tendremos una unica fecha, e introduciremos los datos segun producto y fecha. Por ahora dejaremos en valor nulos aquellas variables que no tengan valor en la fecha elegida. Las variables de **idsecuencia** no se incorporaran al dataset.

```{r}
## Stock y Venta
data_help <- left_join(data_Stock, data_Venta, by=c("producto", "Fecha")) %>%
  dplyr::select(-starts_with("id"))

# Valores nulos generados
sum(is.na(data_help))
# Resumen valores nulos
summary(data_help[!complete.cases(data_help), ])

# Filtramos y quitamos todos los productos en 2023-04-04
data_help <- data_help %>%
  dplyr::filter(Fecha != as.Date("2023-04-04", "%Y-%m-%d"))

# Valors nulls generats
sum(is.na(data_help))

```

Vemos que hemos creado unos cuantos valores nulos al hacer esta combinacion, pero la parte mas importante es que estos valores nulos corresponden al 4 de abril del 2023, todos, por tanto quitaremos esta fecha para seguir funcionando (podriamos predecir el stock con esto, pero no la venta).

```{r}
## Ahora con calendario
data_help <- left_join(data_help, data_Calendario, by=c("Fecha")) %>%
  dplyr::select(-starts_with("id"))

# Valores nulos generados
print(sum(is.na(data_help)))
```

En este caso, al querer hacer la union con el calendario de apertura o de festivo, obtenemos que no hay informacion de ningun tipo en el dia 4 de abril de 2021, correspondiente al primer dia de reserva de datos, quitaremos esta fecha y miraremos si podemos trabajar los stocks mas adelante.



```{r}
## Con Ciclo
data_help <- full_join(data_help, data_Ciclo, by=c("producto"))

# Valores nulos generados
sum(is.na(data_help))
# Resumen valores nulos
summary(data_help[!complete.cases(data_help), ])

# Vemos los productos que dan valores nulos
data_help[!complete.cases(data_help), ]$producto

# Estos productos son los que no se encuentran en Datos, asi que seran eliminados.
data_help <- na.omit(data_help)

# Valores nulos generados
sum(is.na(data_help))
# Resumen valores nulos
summary(data_help)

```

```{r}
## PRECIO
data_help <- left_join(data_help, data_Precio, by=c("producto"))

# Valores nulos generados
sum(is.na(data_help))

# Vemos como es
head(data_help)
```



```{r}
## PROMO, MEJORAR, REPITE POR CADA PRODUCTO, MEJORAR REVISAR ESTE
data_Promo <- data_Promo %>%
   dplyr::select(-starts_with("id"))
data_help <- data_help
for (i in unique(data_help$producto)) {
  # Subconjunto de la tabla de intervalos de fechas para el producto actual
  intervalos <- data_Promo[data_Promo$producto == i,]
  
  # Crea una nueva variable booleana para el producto actual
  data_help$promo_activated[data_help$producto == i] <- FALSE
  
    # Itera a través de cada intervalo de fechas para el producto actual y verifica si la fecha diaria se encuentra dentro del intervalo
  for (j in 1:nrow(intervalos)) {
    data_help$promo_activated[data_help$producto == i & 
                                  data_help$Fecha >=intervalos$FechaIni[j] & 
                                  data_help$Fecha <= intervalos$FechaFin[j]] <- TRUE
  }
}

data_help$promo_activated <- as.numeric(data_help$promo_activated)
```

## Estudio Stock

```{r, warning = FALSE}
## Veiem Dades amb estoc nul o negatiu
data_summarise <- data_help %>%
  dplyr::summarise(
    stock_mal = ifelse(udsStock <= 0, TRUE, FALSE),
    venta_negatiu = ifelse(udsVenta < 0, TRUE, FALSE)
  )
## Si hi ha stock negatiu, posarem un valor nul en les ventes
table(data_summarise)
```

Llegados a este punto, nos tenemos que preguntar, porque hay ventas negativas? y stock negativo? Podemos suponer que el stock negativo viene causado por rotura del producto en el almacen, mientras que las ventas negativas pueden darse de producto servido pero des de otro centro logistico. De un total con 705672 entradas tenemos 16052 valores extraños. Estos valores se han de modificar, pero que criterio usamos? la media de los dias anteriores? los ponemos como valor 0? Hay muchas maneras de trabajar con valores nulos, pero es necesario encontrar una manera correcta. Haremos la sustitucion de los valores nulos con media movil de 5 dias anteriores

```{r}
data_help <- data_help %>%
  group_by(producto) %>%
  arrange(Fecha) %>%
  dplyr::mutate(
    udsVenta = ifelse(udsVenta < 0 | udsStock <= 0, 
                      NA, 
                      udsVenta)
  ) %>%
  ungroup()

print(sum(is.na(data_help$udsVenta)))

data_help <- data_help %>%
  group_by(producto) %>%
  arrange(Fecha) %>%
  dplyr::mutate(
    udsVenta = if_else(is.na(udsVenta),
                       zoo::rollapply(data = udsVenta,
                                      width = 5,
                                      FUN = mean,
                                      fill = NA,
                                      align = "right"),
                       udsVenta)
  ) %>%
  ungroup()

print(sum(is.na(data_help$udsVenta)))
```

Viendo que no conseguimos quitar todos los valores nulos, ya que parece ser que hay dis consecutivos con incocistencias, optaremos actualmente por ponerlos todos a 0, veremos que otra solucion podemos aplicar para mejorar los resultados.

EN FESTIVO SE VENDE?

```{r}
data_help <- data_help %>%
  group_by(producto) %>%
  arrange(Fecha) %>%
  dplyr::mutate(
    udsVenta = if_else(is.na(udsVenta) | bolHoliday == 1,
                       0,
                       udsVenta)) %>%
  ungroup() %>%
  select(-udsStock)
print(sum(is.na(data_help$udsVenta)))

## Comrpovamos si el festivo se vende
print(nrow(data_help %>% filter(udsVenta != 0 & bolHoliday == 1)))
```

Ahora, partiremos de este data set para los diferntes modelos. Hacemos notar que segun el modelo que tiremos los dias festivos pueden ser un problema, asi que segun modelo, como Arimax o el Multiple Linear Regression, los dias festivos seran eliminados en el conjunto de datos y no se usaran ni para el entrenamiento ni test.

Por ultimo, comentamos que para ver los resultados haremos listas anidadas, enfocandonos en cada producto, y haciendo una lista anidada con la suma de todos ellos.
















# Analisis de les dades
## Serie temporal de los datos

Vamos a ver como es la serie temporal de los datos y su descomposicion, primero agruparemos los datos de todos los productos en uno global.
```{r}
# Creamos la agrupacion
datos_all <- data_help %>% 
  dplyr::group_by(Fecha) %>%
  dplyr::summarise(
    udsVenta = sum(udsVenta)
  )

# Creamos la serie temporal de la agrupacion
serie <- ts(datos_all$udsVenta, start = c(2021, 95), frequency = 365)
descom <- decompose(serie)

# Observamos la descomposicion en sus componentes
plot(descom)

# Creamos un data frame con los componentes
df_descom <- data.frame(
  Fecha = time(serie),  # Columna de fechas
  Observado = descom$x,
  Tendencia = descom$trend,  # Componente de tendencia
  Estacionalidad = descom$seasonal,  # Componente de estacionalidad
  Ruido = descom$random  # Componente de residuos
)

# Observado
ggplot(data = df_descom, aes(x = Fecha, y = Observado)) + geom_line()
# Tendencia
ggplot(data = df_descom, aes(x = Fecha, y = Tendencia)) + geom_line()
# Estacionalidad del 2022, se repite para todos los años
ggplot(data = df_descom %>% filter(floor(Fecha) == 2022), aes(x = Fecha, y = Estacionalidad)) + geom_line()
# Ruido
ggplot(data = df_descom, aes(x = Fecha, y = Ruido)) + geom_line()
```

Como en nuestra serie temporal tenemos muchos 0, vemos que esto se queda en la estacionalida (ya que son todos los domingos), pero tambien provoca que sea dificil la lectura visual de los datos, vamos a eliminar todos aquellos dias que la tienda ha estado cerrada, y vemos como queda la descomposicion.

```{r}

# Creamos la agrupacion
datos_all_filtro <- data_help %>% 
  dplyr::filter(bolOpen == 1) %>%
  dplyr::group_by(Fecha) %>%
  dplyr::summarise(
    udsVenta = sum(udsVenta)
  )

# Dias laborables del primer año completo
Dias <- nrow(datos_all_filtro  %>% filter(year(Fecha) == 2022))

# Creamos la serie temporal de la agrupacion, como no tenemos festivos entonces los dias laborables son 307, los del 2022
serie_filtro <- ts(datos_all_filtro$udsVenta, start = c(2021, 95), frequency = Dias)
descom_filtro <- decompose(serie_filtro)

# Observamos la descomposicion en sus componentes
plot(descom)

# Creamos un data frame con los componentes
df_descom_filtro <- data.frame(
  Fecha = time(serie_filtro),  # Columna de fechas
  Observado = descom_filtro$x,
  Tendencia = descom_filtro$trend,  # Componente de tendencia
  Estacionalidad = descom_filtro$seasonal,  # Componente de estacionalidad
  Ruido = descom_filtro$random  # Componente de residuos
)

# Observado
ggplot(data = df_descom_filtro, aes(x = Fecha, y = Observado)) + geom_line()
# Tendencia
ggplot(data = df_descom_filtro, aes(x = Fecha, y = Tendencia)) + geom_line()
# Estacionalidad del 2022, se repite para todos los años
ggplot(data = df_descom_filtro %>% filter(floor(Fecha) == 2022), aes(x = Fecha, y = Estacionalidad)) + geom_line()
# Ruido
ggplot(data = df_descom_filtro, aes(x = Fecha, y = Ruido)) + geom_line()
```

Hemos realizado una limpieza sobre los datos, pero aun tenemos muchos problemas con estos, vamos a quitar aquellos dias con ventas 0.

```{r}
# Creamos la agrupacion
datos_all_filtro <- data_help %>% 
  dplyr::filter(udsVenta != 0) %>%
  dplyr::group_by(Fecha) %>%
  dplyr::summarise(
    udsVenta = sum(udsVenta)
  )

# Dias laborables del primer año completo
Dias <- nrow(datos_all_filtro  %>% filter(year(Fecha) == 2022))

# Creamos la serie temporal de la agrupacion, como no tenemos festivos entonces los dias laborables son 307, los del 2022
serie_filtro <- ts(datos_all_filtro$udsVenta, start = c(2021, 95), frequency = Dias)
descom_filtro <- decompose(serie_filtro)

# Observamos la descomposicion en sus componentes
plot(descom)

# Creamos un data frame con los componentes
df_descom_filtro <- data.frame(
  Fecha = time(serie_filtro),  # Columna de fechas
  Observado = descom_filtro$x,
  Tendencia = descom_filtro$trend,  # Componente de tendencia
  Estacionalidad = descom_filtro$seasonal,  # Componente de estacionalidad
  Ruido = descom_filtro$random  # Componente de residuos
)

# Observado
ggplot(data = df_descom_filtro, aes(x = Fecha, y = Observado)) + geom_line()
# Tendencia
ggplot(data = df_descom_filtro, aes(x = Fecha, y = Tendencia)) + geom_line()
# Estacionalidad del 2022, se repite para todos los años
ggplot(data = df_descom_filtro %>% filter(floor(Fecha) == 2022), aes(x = Fecha, y = Estacionalidad)) + geom_line()
# Ruido
ggplot(data = df_descom_filtro, aes(x = Fecha, y = Ruido)) + geom_line()
```

En este punto observamos como han evolucionado los datos en general omitiendo los productos que no han vendido en ese dia, vemos que en global los productos tienen ventas un poco aleatorias, recordemos que apenas tenemos dos años de observaciones y la estacionalidad es anual. 
# Modelos
## Conjunt entrenament / test

En el mundo laboral, habitualmente se suele emprar el conjunto de datos de entrenamiento los años anteriores al ultimo que se tiene registro, y este ultimo como datos de muestreo. Como tenemos 2 años de observacion, utilizaremos los meses de 2023 como el conjunto de test, y los datos anteriores a este como el conjunto de entrenamiento. Tambien seria factible usar solo los 30 ultimos dias como conjunto de test.
### Conjunto de entrenamiento: DATOS DE ESTE AÑO
```{r}
df_train <- data_help %>%
  filter( Fecha < as.Date("2023-01-01"))
df_test <- data_help %>%
  filter( Fecha >= as.Date("2023-01-01"))

df_train_all <- data_help %>%
  filter( Fecha < as.Date("2023-01-01")) %>%
  group_by(Fecha) %>%
  dplyr::summarise(
    udsVenta = sum(udsVenta)
  )

df_test_all <- data_help %>%
  filter( Fecha >= as.Date("2023-01-01")) %>%
  group_by(Fecha) %>%
  dplyr::summarise(
    udsVenta = sum(udsVenta)
  )
```

## ARIMA / ARIMAX

Vamos a ver como es la serie temporal de los datos.
### Global

```{r}
serie_test <- ts(df_train_all$udsVenta, start = c(2021, 95), frequency = 365)
serie_train <- ts(df_test_all$udsVenta, start = c(2023, 01), frequency = nrow(df_test_all))

arima_all <- auto.arima(serie_test)
fore_arima_all <- forecast(arima_all, h = nrow(df_test_all))
arima_all_rmse <- sqrt(mean((as.vector(fore_arima_all$mean) - as.vector(df_test_all$udsVenta))^2))
```

#### PLOT

```{r}
plot(fore_arima_all, main = "Predicciones ARIMA", xlab = "Fecha", ylab = "Unidades Vendidas")
lines(df_test_all$Fecha, df_test_all$udsVenta, col = "blue", type = "l", lwd = 2)  # Datos reales
lines(fore_arima_all$mean, col = "red", type = "l", lwd = 2)  # Predicciones


# Mostrar el error RMSE en la gráfica
legend("topleft", legend = paste("RMSE:", round(arima_all_rmse, 2)), col = "black", lwd = 1, bty = "n")
```




### Construimos nuestros datasets con pecularidades a nivel producto
```{r}
# Como no se venden en dias festivos, quitaremos las filas correspondientes a dias festivos.
df_train2 <- df_train %>%
  dplyr::filter(bolOpen != 0)

df_test2 <- df_test %>%
  dplyr::filter(bolOpen != 0)

# Creamos dos series temporales, una corresponde a las ventas del producto y otra los periodos en ofertas.
# Separamos cada data frame a listas
df_list_train <- split(df_train2, df_train2$producto)
df_list_test <- split(df_test2, df_test2$producto)
df_ARIMA <- vector(mode = "list", length = length(unique(data_help$producto)))

# Preparamos los diferentes datasets
for (i in 1:length(unique(data_help$producto))) {
  df_list_train[[i]] <- as.list(df_list_train[[i]])
  df_ARIMA[[i]]$udsVenta <- ts(df_list_train[[i]]$udsVenta, start = c(2021, 95), frequency = 365)
  df_ARIMA[[i]]$udsPromo <- ts(df_list_train[[i]]$promo_activated, start = c(2021, 95), frequency = 365)
  df_ARIMA[[i]]$diasEntrePedidos <- mean(df_list_train[[i]]$diasEntrePedido)
  df_ARIMA[[i]]$diasLeadtime <- mean(df_list_train[[i]]$diasLeadtime)
  df_ARIMA[[i]]$eurPrecioMedio <- mean(df_list_train[[i]]$eurPrecioMedio)
  df_ARIMA[[i]]$Producto <- i
  df_list_test[[i]] <- as.list(df_list_test[[i]])
  df_ARIMA[[i]]$udsVenta_test <- ts(df_list_test[[i]]$udsVenta, start = c(2023, 01), frequency = 365)
  df_ARIMA[[i]]$udsPromo_test <- ts(df_list_test[[i]]$promo_activated, start = c(2023, 01), frequency = 365)
}
```

### ARIMA POR PRDUCTO
```{r, warning = FALSE}
ARIMAX_rmse_spr <- c()
ARIMAX_rmse_pr <- c()

for (i in 1:length(unique(data_help$producto))) {
  # SIN VARIABLE DE PROMOCIONES
  df_ARIMA[[i]]$model_sinpr <- tryCatch(auto.arima(df_ARIMA[[i]]$udsVenta),
                      error = function(e) NULL)
  
  if (!is.null(df_ARIMA[[i]]$model_sinpr)) {
    df_ARIMA[[i]]$pred_sinpr <- forecast(df_ARIMA[[i]]$model_sinpr, h = nrow(df_test2))
    df_ARIMA[[i]]$rmse_sinpr <- sqrt(mean((as.vector(df_ARIMA[[i]]$pred_sinpr$mean) - as.vector(df_ARIMA[[i]]$udsVenta_test))^2))
    ARIMAX_rmse_spr <- c(ARIMAX_rmse_spr, sqrt(mean((as.vector(df_ARIMA[[i]]$pred_sinpr$mean) - as.vector(df_ARIMA[[i]]$udsVenta_test))^2)))
  }
  
  # CON VARIABLE DE PROMOCIONES
  df_ARIMA[[i]]$model_pr <- tryCatch(auto.arima(df_ARIMA[[i]]$udsVenta, xreg = df_ARIMA[[i]]$udsPromo),
                      error = function(e) NULL)
  
  if (!is.null(df_ARIMA[[i]]$model_pr)) {
    df_ARIMA[[i]]$pred_pr <- forecast(df_ARIMA[[i]]$model_pr, h = nrow(df_test2), xreg = df_ARIMA[[i]]$udsPromo_test)
    df_ARIMA[[i]]$rmse_pr <- sqrt(mean((as.vector(df_ARIMA[[i]]$pred_pr$mean) - as.vector(df_ARIMA[[i]]$udsVenta_test))^2))
    ARIMAX_rmse_pr <- c(ARIMAX_rmse_pr, sqrt(mean((as.vector(df_ARIMA[[i]]$pred_pr$mean) - as.vector(df_ARIMA[[i]]$udsVenta_test))^2)))
  }
}

```

```{r}
factor_servicio <- 1.64 # Nivel de servicio del 95%

for (i in 1:length(unique(data_help$producto))) {
  
  ciclo_aprovisionamiento <- df_ARIMA[[i]]$diasLeadtime
  coste_unitario_pct <- df_ARIMA[[i]]$eurPrecioMedio
    # Calculamos el stock de seguridad sólo si se ha ajustado un modelo
  if (!is.null(df_ARIMA[[i]]$model_sinpr) | !is.null(df_ARIMA[[i]]$model_pr)) {
    # Calculamos el stock de seguridad para ambos modelos
    df_ARIMA[[i]]$stock_seguridad_sinpr <- factor_servicio * df_ARIMA[[i]]$rmse_sinpr * sqrt(ciclo_aprovisionamiento)
    df_ARIMA[[i]]$stock_seguridad_pr <- factor_servicio * df_ARIMA[[i]]$rmse_pr * sqrt(ciclo_aprovisionamiento)
    
    # Calculamos el coste del stock para ambos modelos
    df_ARIMA[[i]]$coste_stock_sinpr <- coste_unitario_pct * df_ARIMA[[i]]$eurPrecioMedio * df_ARIMA[[i]]$stock_seguridad_sinpr
    df_ARIMA[[i]]$coste_stock_pr <- coste_unitario_pct * df_ARIMA[[i]]$eurPrecioMedio * df_ARIMA[[i]]$stock_seguridad_pr
  }
}

```
##### PRUEBAS PLOT

```{r}


# Seleccionamos un producto
producto <- df_ARIMA[[278]]

# Crear un data frame con los datos para el gráfico
df_plot <- data.frame(
  Fecha = c(time(producto$udsVenta), time(producto$pred_sinpr$mean)[1:length(producto$udsVenta_test)], time(producto$pred_pr$mean)[1:length(producto$udsVenta_test)]),
  Valor = c(as.vector(producto$udsVenta), as.vector(producto$pred_sinpr$mean)[1:length(producto$udsVenta_test)], as.vector(producto$pred_pr$mean)[1:length(producto$udsVenta_test)]),
  Tipo = c(rep("Ventas", length(producto$udsVenta)), rep("Prediccion sin promociones", length(producto$udsVenta_test)), rep("Prediccion con promociones", length(producto$udsVenta_test)))
)



# Crear el gráfico de líneas de ventas y predicciones
ggplot(df_plot, aes(x = Fecha, y = Valor, color = Tipo)) +
  geom_line() +
  labs(title = paste("Producto", producto$Producto), y = "Unidades", x = "Fecha", color = "Tipo") +
  theme_minimal()

# Crear un gráfico de barras para los costos de almacenamiento
df_cost <- data.frame(
  Tipo = c("Coste sin promociones", "Coste con promociones"),
  Coste = c(producto$coste_stock_sinpr, producto$coste_stock_pr)
)

ggplot(df_cost, aes(x = Tipo, y = Coste, fill = Tipo)) +
  geom_bar(stat = "identity") +
  labs(title = paste("Coste de almacenamiento del producto", producto$Producto), y = "Coste", x = "", fill = "Tipo") +
  theme_minimal()

```

### CONOCLUSIONS ARIMA


## Suavizado exponencial


### Nivel General

```{r}
# Conjunto entrenamiento test, igual que el Arima
df_train_all <- data_help %>%
  filter( Fecha < as.Date("2023-01-01")) %>%
  group_by(Fecha) %>%
  dplyr::summarise(
    udsVenta = sum(udsVenta)
  )

df_test_all <- data_help %>%
  filter( Fecha >= as.Date("2023-01-01")) %>%
  group_by(Fecha) %>%
  dplyr::summarise(
    udsVenta = sum(udsVenta)
  )

# Aplicar el suavizado exponencial
modelo_exp <- ets(df_train_all$udsVenta)

# Generar las predicciones
predicciones_exp <- forecast(modelo_exp, nrow(df_test_all))

# Calcular el RMSE
rmse_exp <- sqrt(mean((predicciones_exp$mean - df_test_all$udsVenta)^2))

# Graficar las predicciones
# plot(predicciones_exp, type = "l", col = "red", lwd = 2, main = "Predicciones Suavizado Exponencial",
#      xlab = "Fecha", ylab = "Unidades Vendidas")
# lines(df_test_all$Fecha, df_test_all$udsVenta, col = "blue", type = "l", lwd = 2)  # Datos reales
# legend("topright", legend = c("Predicciones", "Datos Reales"), col = c("red", "blue"), lwd = 2)
```

Hem de comprobar amb dies tancats, per si millora a nivel global.

```{r}
# Conjunto entrenamiento test, igual que el Arima
df_train_all <- data_help %>%
  filter(bolOpen != 0) %>%
  filter( Fecha < as.Date("2023-01-01")) %>%
  group_by(Fecha) %>%
  dplyr::summarise(
    udsVenta = sum(udsVenta)
  )

df_test_all <- data_help %>%
  filter(bolOpen != 0) %>%
  filter( Fecha >= as.Date("2023-01-01")) %>%
  group_by(Fecha) %>%
  dplyr::summarise(
    udsVenta = sum(udsVenta)
  )

# Aplicar el suavizado exponencial
modelo_exp <- ets(df_train_all$udsVenta)

# Generar las predicciones
predicciones_exp <- forecast(modelo_exp, nrow(df_test_all))

# Calcular el RMSE
rmse_exp <- sqrt(mean((predicciones_exp$mean - df_test_all$udsVenta)^2))

# Graficar las predicciones
# plot(predicciones_exp, type = "l", col = "red", lwd = 2, main = "Predicciones Suavizado Exponencial",
#      xlab = "Fecha", ylab = "Unidades Vendidas")
# lines(df_test_all$Fecha, df_test_all$udsVenta, col = "blue", type = "l", lwd = 2)  # Datos reales
# legend("topright", legend = c("Predicciones", "Datos Reales"), col = c("red", "blue"), lwd = 2)
```

### Construimos nuestros datasets con pecularidades a nivel producto
```{r}
# Como no se venden en dias festivos, quitaremos las filas correspondientes a dias festivos, ya que crean ruido.
df_train2 <- df_train %>%
  dplyr::filter(bolOpen != 0)

df_test2 <- df_test %>%
  dplyr::filter(bolOpen != 0)

# Creamos dos series temporales, una corresponde a las ventas del producto y otra los periodos en ofertas.
# Separamos cada data frame a listas
df_list_train <- split(df_train2, df_train2$producto)
df_list_test <- split(df_test2, df_test2$producto)
df_EXPS <- vector(mode = "list", length = length(unique(data_help$producto)))

# Preparamos los diferentes datasets
for (i in 1:length(unique(data_help$producto))) {
  df_list_train[[i]] <- as.list(df_list_train[[i]])
  df_EXPS[[i]]$data <- data.frame(Fecha = df_list_train[[i]]$Fecha,
                                  udsVenta = df_list_train[[i]]$udsVenta,
                                  promo_activated = df_list_train[[i]]$promo_activated)
  df_EXPS[[i]]$diasEntrePedidos <- mean(df_list_train[[i]]$diasEntrePedido)
  df_EXPS[[i]]$diasLeadtime <- mean(df_list_train[[i]]$diasLeadtime)
  df_EXPS[[i]]$eurPrecioMedio <- mean(df_list_train[[i]]$eurPrecioMedio)
  df_EXPS[[i]]$Producto <- i
  df_list_test[[i]] <- as.list(df_list_test[[i]])
  df_EXPS[[i]]$data_test <- data.frame(Fecha = df_list_test[[i]]$Fecha,
                                  udsVenta = df_list_test[[i]]$udsVenta,
                                  promo_activated = df_list_test[[i]]$promo_activated)
}
```

### EXPS POR PRDUCTO
```{r, warning = FALSE}
EXPS_rmse_spr <- c()
EXPS_rmse_pr <- c()

for (i in 1:length(unique(data_help$producto))) {
  # SIN VARIABLE DE PROMOCIONES
  df_EXPS[[i]]$model_sinpr <- tryCatch(ets(df_EXPS[[i]]$data$udsVenta),
                      error = function(e) NULL)
  
  if (!is.null(df_EXPS[[i]]$model_sinpr)) {
    df_EXPS[[i]]$pred_sinpr <- forecast(df_EXPS[[i]]$model_sinpr, h = nrow(df_test2))
    df_EXPS[[i]]$rmse_sinpr <- sqrt(mean((as.vector(df_EXPS[[i]]$pred_sinpr$mean) - as.vector(df_EXPS[[i]]$data_test$udsVenta))^2))
    EXPS_rmse_spr <- c(EXPS_rmse_spr, sqrt(mean((as.vector(df_EXPS[[i]]$pred_sinpr$mean) - as.vector(df_EXPS[[i]]$data_test$udsVenta))^2)))
  }
}
```

No he podido añadir variables regresosar al modelo exponential smoothing. Asi que analizaremos los datos solo con variables de venta.

```{r}
factor_servicio <- 1.64 # Nivel de servicio del 95%

for (i in 1:length(unique(data_help$producto))) {
  
  ciclo_aprovisionamiento <- df_EXPS[[i]]$diasLeadtime
  coste_unitario_pct <- df_EXPS[[i]]$eurPrecioMedio
    # Calculamos el stock de seguridad sólo si se ha ajustado un modelo
  if (!is.null(df_EXPS[[i]]$model_sinpr) | !is.null(df_EXPS[[i]]$model_pr)) {
    # Calculamos el stock de seguridad para ambos modelos
    df_EXPS[[i]]$stock_seguridad_sinpr <- factor_servicio * df_EXPS[[i]]$rmse_sinpr * sqrt(ciclo_aprovisionamiento)
    df_EXPS[[i]]$stock_seguridad_pr <- factor_servicio * df_EXPS[[i]]$rmse_pr * sqrt(ciclo_aprovisionamiento)
  }
}

```

##### PRUEBAS PLOT

```{r}

```

## PROPHET A VEURE

### NIVEL GLOBAL

```{r}
df_train <- data_help %>%
  filter( Fecha < as.Date("2023-01-01"))
df_test <- data_help %>%
  filter( Fecha >= as.Date("2023-01-01"))

df_train_all <- data_help %>%
  filter(Fecha < as.Date("2023-01-01")) %>%
  group_by(Fecha) %>%
  dplyr::summarise(
    y = sum(udsVenta)
  )

colnames(df_train_all) <- c("ds", "y")

df_test_all <- data_help %>%
  filter(Fecha >= as.Date("2023-01-01")) %>%
  group_by(Fecha) %>%
  dplyr::summarise(
    y = sum(udsVenta)
  )

colnames(df_test_all) <- c("ds", "y")
```

```{r}
modelo_prophet_all <- prophet(daily.seasonality = TRUE, yearly.seasonality = FALSE)

modelo_prophet_all <- fit.prophet(modelo_prophet_all, df_train_all)
forecast_prophet_all <- predict(modelo_prophet_all, df_test_all)
rmse_prophet_all <- sqrt(mean((as.vector(forecast_prophet_all$yhat) - as.vector(df_test_all$y))^2))

plot(modelo_prophet_all, forecast_prophet_all)


```

Els 0 creen problemes en el prophet !!!, no utilitzarem les dades on la tenda ha estat tancada

```{r}
df_train_all <- data_help %>%
  filter(bolOpen != 0) %>%
  filter(Fecha < as.Date("2023-01-01")) %>%
  group_by(Fecha) %>%
  dplyr::summarise(
    y = sum(udsVenta)
  )

colnames(df_train_all) <- c("ds", "y")

df_test_all <- data_help %>%
  filter(bolOpen != 0) %>%
  filter(Fecha >= as.Date("2023-01-01")) %>%
  group_by(Fecha) %>%
  dplyr::summarise(
    y = sum(udsVenta)
  )

colnames(df_test_all) <- c("ds", "y")


modelo_prophet_all <- prophet(daily.seasonality = TRUE, yearly.seasonality = FALSE)

modelo_prophet_all <- fit.prophet(modelo_prophet_all, df_train_all)
forecast_prophet_all <- predict(modelo_prophet_all, df_test_all)
rmse_prophet_all <- sqrt(mean((as.vector(forecast_prophet_all$yhat) - as.vector(df_test_all$y))^2))

plot(modelo_prophet_all, forecast_prophet_all)


```




### Construimos nuestros datasets con pecularidades
```{r}
# Quitamos los 0
df_train2 <- data_help %>%
  filter(bolOpen != 0) %>%
  filter( Fecha < as.Date("2023-01-01"))
df_test2 <- data_help %>%
  filter(bolOpen != 0) %>%
  filter( Fecha >= as.Date("2023-01-01"))


# Creamos dos series temporales, una corresponde a las ventas del producto y otra los periodos en ofertas.
# Separamos cada data frame a listas
df_list_train <- split(df_train2, df_train$producto)
df_list_test <- split(df_test2, df_test$producto)
df_PROPH <- vector(mode = "list", length = length(unique(data_help$producto)))

# Preparamos los diferentes datasets
for (i in 1:length(unique(data_help$producto))) {
  df_list_train[[i]] <- as.list(df_list_train[[i]])
  df_PROPH[[i]]$datos <- data.frame(ds = df_list_train[[i]]$Fecha,
                                       y = df_list_train[[i]]$udsVenta,
                                       promo = df_list_train[[i]]$promo_activated)
  df_PROPH[[i]]$diasEntrePedidos <- mean(df_list_train[[i]]$diasEntrePedido)
  df_PROPH[[i]]$diasLeadtime <- mean(df_list_train[[i]]$diasLeadtime)
  df_PROPH[[i]]$eurPrecioMedio <- mean(df_list_train[[i]]$eurPrecioMedio)
  df_PROPH[[i]]$Producto <- i
  df_list_test[[i]] <- as.list(df_list_test[[i]])
  df_PROPH[[i]]$datos_test <- data.frame(ds = df_list_test[[i]]$Fecha,
                                       y =df_list_test[[i]]$udsVenta,
                                       promo =df_list_test[[i]]$promo_activated)
}
```

### PROPHET POR PRDUCTO
```{r, warning = FALSE}
PROPHET_rmse_spr <- c()
PROPHET_rmse_pr <- c()

start_time_all <- Sys.time()  # Captura el tiempo de inicio
for (i in 1:length(unique(data_help$producto))) {
  start_time <- Sys.time()  # Captura el tiempo de inicio
  cat("Producto:", i, "\n")  # Muestra el producto actual

  # SIN VARIABLE DE PROMOCIONES
  datos_sinpromo <- df_PROPH[[i]]$datos %>% select(-promo)
  modelo_sinpr <- prophet(daily.seasonality = TRUE, yearly.seasonality = FALSE)
  modelo_sinpr <- fit.prophet(modelo_sinpr, datos_sinpromo)
  temps <- make_future_dataframe(modelo_sinpr, periods = nrow(df_PROPH[[i]]$datos_test))
  df_PROPH[[i]]$forecast_sinpr <- predict(modelo_sinpr, temps)
  df_PROPH[[i]]$rmse_sinpr <- sqrt(mean((as.vector(df_PROPH[[i]]$forecast_sinpr$yhat) - as.vector(df_PROPH[[i]]$datos_test$y))^2))
  PROPHET_rmse_spr <- c(PROPHET_rmse_spr, sqrt(mean((as.vector(df_PROPH[[i]]$forecast_sinpr$yhat) - as.vector(df_PROPH[[i]]$datos_test$y))^2)))

  # CON VARIABLE DE PROMOCIONES
  modelo_pr <- prophet(daily.seasonality = TRUE, yearly.seasonality = FALSE)
  modelo_pr <- add_regressor(modelo_pr, "promo")
  modelo_pr <- fit.prophet(modelo_pr, df_PROPH[[i]]$datos)
  temps <- make_future_dataframe(modelo_pr, periods = nrow(df_PROPH[[i]]$datos_test))
  temps$promo <- rep(df_PROPH[[i]]$datos$promo, length.out = nrow(temps))
  if (!is.null(modelo_pr)) {
    df_PROPH[[i]]$forecast_pr <- predict(modelo_pr, temps)
    df_PROPH[[i]]$rmse_pr <- sqrt(mean((as.vector(df_PROPH[[i]]$forecast_pr$yhat) - as.vector(df_PROPH[[i]]$datos_test$y))^2))
    PROPHET_rmse_pr <- c(PROPHET_rmse_pr, sqrt(mean((as.vector(df_PROPH[[i]]$forecast_pr$yhat) - as.vector(df_PROPH[[i]]$datos_test$y))^2)))
  }
  
  end_time <- Sys.time()  # Captura el tiempo de finalización
  elapsed_time <- end_time - start_time  # Calcula el tiempo transcurrido
  cat("Tiempo transcurrido:", elapsed_time, "segundos\n\n")
  sink()
}
end_time_all <- Sys.time()  # Captura el tiempo de finalización
elapsed_time_all <- end_time_all - start_time_all  # Calcula el tiempo transcurrido
cat("Tiempo transcurrido:", elapsed_time_all, "segundos\n\n")
```




```{r}
factor_servicio <- 1.64 # Nivel de servicio del 95%

for (i in 1:length(unique(data_help$producto))) {
  
  ciclo_aprovisionamiento <- df_ARIMA[[i]]$diasLeadtime
  coste_unitario_pct <- df_ARIMA[[i]]$eurPrecioMedio
    # Calculamos el stock de seguridad sólo si se ha ajustado un modelo
  if (!is.null(df_ARIMA[[i]]$model_sinpr) | !is.null(df_ARIMA[[i]]$model_pr)) {
    # Calculamos el stock de seguridad para ambos modelos
    df_PROPH[[i]]$stock_seguridad_sinpr <- factor_servicio * df_PROPH[[i]]$rmse_sinpr * sqrt(ciclo_aprovisionamiento)
    df_PROPH[[i]]$stock_seguridad_pr <- factor_servicio * df_PROPH[[i]]$rmse_pr * sqrt(ciclo_aprovisionamiento)
    
    # Calculamos el coste del stock para ambos modelos
    df_PROPH[[i]]$coste_stock_sinpr <- coste_unitario_pct * df_PROPH[[i]]$eurPrecioMedio * df_PROPH[[i]]$stock_seguridad_sinpr
    df_PROPH[[i]]$coste_stock_pr <- coste_unitario_pct * df_PROPH[[i]]$eurPrecioMedio * df_PROPH[[i]]$stock_seguridad_pr
  }
}
```

















## NAIVE (Este se suposa que es facil) NO FET


```{r}
df_train <- data_help %>%
  filter( Fecha < as.Date("2023-01-01"))
df_test <- data_help %>%
  filter( Fecha >= as.Date("2023-01-01"))

df_train_all <- data_help %>%
  filter( Fecha < as.Date("2023-01-01")) %>%
  group_by(Fecha) %>%
  dplyr::summarise(
    udsVenta = sum(udsVenta)
  )

df_test_all <- data_help %>%
  filter( Fecha >= as.Date("2023-01-01")) %>%
  group_by(Fecha) %>%
  dplyr::summarise(
    udsVenta = sum(udsVenta)
  )
```


### Nivell global

```{r}
serie_train <- ts(df_train_all$udsVenta, start = c(2021, 95), frequency = 365)
serie_test <- ts(df_test_all$udsVenta, start = c(2023, 01), frequency = nrow(df_test_all))

# Aplicar el método Naive
naive_forecast <- naive(serie_train, h = nrow(df_test_all))

# Calcular el error RMSE
rmse <- sqrt(mean((naive_forecast$mean - df_test_all$udsVenta)^2))

# Graficar los resultados
plot(df_test_all$Fecha, df_test_all$udsVenta, type = "l", col = "blue", xlab = "Fecha", ylab = "Unidades Vendidas", main = "Método Naive")
lines(df_test_all$Fecha, naive_forecast$mean, type = "l", col = "red")
legend("topleft", legend = paste("RMSE:", round(rmse, 2)), col = "black", lwd = 1, bty = "n")
```

Sense 0

```{r}

df_train_all_filtro <- data_help %>%
  filter(bolOpen != 0) %>%
  filter( Fecha < as.Date("2023-01-01")) %>%
  group_by(Fecha) %>%
  dplyr::summarise(
    udsVenta = sum(udsVenta)
  )

df_test_all_filtro <- data_help %>%
  filter(bolOpen != 0) %>%
  filter( Fecha >= as.Date("2023-01-01")) %>%
  group_by(Fecha) %>%
  dplyr::summarise(
    udsVenta = sum(udsVenta)
  )

Dias <- nrow(df_train_all_filtro %>% filter(year(Fecha) == 2022))

serie_train_filtro <- ts(df_train_all$udsVenta, start = c(2021, 95), frequency = Dias)
serie_test_filtro <- ts(df_test_all$udsVenta, start = c(2023, 01), frequency = nrow(df_test_all))


# Aplicar el método Naive
naive_forecast <- naive(serie_train_filtro, h = nrow(df_test_all_filtro))

# Calcular el error RMSE
rmse <- sqrt(mean((naive_forecast$mean - df_test_all_filtro$udsVenta)^2))

# Graficar los resultados
plot(df_test_all_filtro$Fecha, df_test_all_filtro$udsVenta, type = "l", col = "blue", xlab = "Fecha", ylab = "Unidades Vendidas", main = "Método Naive")
lines(df_test_all_filtro$Fecha, naive_forecast$mean, type = "l", col = "red")
legend("topleft", legend = paste("RMSE:", round(rmse, 2)), col = "black", lwd = 1, bty = "n")
```

### A nivel producto
### Construimos nuestros datasets con pecularidades a nivel producto
```{r}
# Como no se venden en dias festivos, quitaremos las filas correspondientes a dias festivos, ya que crean ruido.
df_train2 <- df_train %>%
  dplyr::filter(bolOpen != 0)

df_test2 <- df_test %>%
  dplyr::filter(bolOpen != 0)



# Creamos dos series temporales, una corresponde a las ventas del producto y otra los periodos en ofertas.
# Separamos cada data frame a listas
df_list_train <- split(df_train2, df_train2$producto)
df_list_test <- split(df_test2, df_test2$producto)
df_NAIVE <- vector(mode = "list", length = length(unique(data_help$producto)))

# Preparamos los diferentes datasets
for (i in 1:length(unique(data_help$producto))) {
  df_list_train[[i]] <- as.list(df_list_train[[i]])
  Dias <- sum(year(df_list_train[[1]]$Fecha) == 2022)
  df_NAIVE[[i]]$data <- ts(df_list_train[[i]]$udsVenta, start = c(2021, 95), frequency = Dias)
  df_NAIVE[[i]]$diasEntrePedidos <- mean(df_list_train[[i]]$diasEntrePedido)
  df_NAIVE[[i]]$diasLeadtime <- mean(df_list_train[[i]]$diasLeadtime)
  df_NAIVE[[i]]$eurPrecioMedio <- mean(df_list_train[[i]]$eurPrecioMedio)
  df_NAIVE[[i]]$Producto <- i
  df_NAIVE[[i]]$data_test <- data.frame(udsVenta = df_list_test[[i]]$udsVenta)
}
```

### NAIVE POR PRDUCTO

```{r}
NAIVE_rmse_spr <- c()

for (i in 1:length(unique(data_help$producto))) {
  # SIN VARIABLE DE PROMOCIONES
  df_NAIVE[[i]]$model_sinpr <- tryCatch(naive(df_NAIVE[[i]]$data, h = nrow(df_NAIVE[[i]]$data_test)),
                      error = function(e) NULL)
  
  if (!is.null(df_NAIVE[[i]]$model_sinpr)) {
    df_NAIVE[[i]]$rmse_sinpr <- sqrt(mean((as.vector(df_NAIVE[[i]]$model_sinpr$mean) - as.vector(df_NAIVE[[i]]$data_test$udsVenta))^2))
    NAIVE_rmse_spr <- c(NAIVE_rmse_spr, df_NAIVE[[i]]$rmse_sinpr)
  }
}

```


No he podido añadir variables regresosar al modelo exponential smoothing. Asi que analizaremos los datos solo con variables de venta.

```{r}
factor_servicio <- 1.64 # Nivel de servicio del 95%

for (i in 1:length(unique(data_help$producto))) {
  
  ciclo_aprovisionamiento <- df_NAIVE[[i]]$diasLeadtime
  coste_unitario_pct <- df_NAIVE[[i]]$eurPrecioMedio
    # Calculamos el stock de seguridad sólo si se ha ajustado un modelo
  if (!is.null(df_NAIVE[[i]]$model_sinpr) | !is.null(df_NAIVE[[i]]$model_pr)) {
    # Calculamos el stock de seguridad para ambos modelos
    df_NAIVE[[i]]$stock_seguridad_sinpr <- factor_servicio * df_NAIVE[[i]]$rmse_sinpr * sqrt(ciclo_aprovisionamiento)
  }
}

```


## GBM
### Tirem uns gbm a tot el conjunt
```{r}
df_train_gbm <- df_train %>% 
  mutate(
    dia = day(Fecha),
    mes = month(Fecha),
    any = year(Fecha),
    dia_semana = wday(Fecha, label = FALSE)
  ) %>%
  select(-Fecha)
```

```{r}
df_test_gbm <- df_test %>%
  mutate(
    dia = day(Fecha),
    mes = month(Fecha),
    any = year(Fecha),
    dia_semana = wwday(Fecha, label = FALSE)
  ) %>%
  select(-Fecha)
```

### Provem a fer un gbm per producte

#### Arreglo datos
```{r, eval = FALSE}
df_list_train <- split(df_train_gbm, df_train$producto)
df_list_test <- split(df_test_gbm, df_test$producto)
df_GBM <- vector(mode = "list", length = 1000)

# Preparamos los diferentes datasets
for (i in 1:length(unique(data_help$producto))) {
  df_list_train[[i]] <- as.list(df_list_train[[i]])
  df_GBM[[i]]$sinpr <- data.frame(df_list_train[[i]]$dia, df_list_train[[i]]$mes, df_list_train[[i]]$any, df_list_train[[i]]$bolOpen, df_list_train[[i]]$udsVenta)
  names(df_GBM[[i]]$sinpr) <- c("dia", "mes", "any", "obert", "venta")
  df_GBM[[i]]$pr <- data.frame(df_list_train[[i]]$dia, df_list_train[[i]]$mes, df_list_train[[i]]$any, df_list_train[[i]]$bolOpen, df_list_train[[i]]$udsVenta, 
                               df_list_train[[i]]$promo_activated)
  names(df_GBM[[i]]$pr) <- c("dia", "mes", "any", "obert", "venta", "promo")
  df_GBM[[i]]$diasEntrePedidos <- mean(df_list_train[[i]]$diasEntrePedido)
  df_GBM[[i]]$diasLeadtime <- mean(df_list_train[[i]]$diasLeadtime)
  df_GBM[[i]]$eurPrecioMedio <- mean(df_list_train[[i]]$eurPrecioMedio)
  df_GBM[[i]]$Producto <- i
  df_list_test[[i]] <- as.list(df_list_test[[i]])
  df_GBM[[i]]$sinpr_test <- data.frame(df_list_test[[i]]$dia, df_list_test[[i]]$mes, df_list_test[[i]]$any, df_list_test[[i]]$bolOpen, df_list_test[[i]]$udsVenta)
  names(df_GBM[[i]]$sinpr_test) <- c("dia", "mes", "any", "obert", "venta")
  df_GBM[[i]]$pr_test <- data.frame(df_list_test[[i]]$dia, df_list_test[[i]]$mes, df_list_test[[i]]$any, df_list_test[[i]]$bolOpen, df_list_test[[i]]$udsVenta,df_list_test[[i]]$promo_activated)
  names(df_GBM[[i]]$pr_test) <- c("dia", "mes", "any", "obert", "venta", "promo")
}
```

```{r, warning = FALSE, message = FALSE, eval = FALSE}
GBM_rmse_spr <- c()
GBM_rmse_pr <- c()
for (i in 1:length(unique(data_help$producto))) {
  df_GBM[[i]]$gbm_sinpr <- gbm(venta ~.,
                               data = df_GBM[[i]]$sinpr,
                               distribution = "gaussian")
  
  df_GBM[[i]]$predict_gbm_sinpr <- predict(df_GBM[[i]]$gbm_sinpr,
                                           newdata = df_GBM[[i]]$sinpr_test)
  df_GBM[[i]]$rmse_gbm_sinpr <- sqrt(mean((df_GBM[[i]]$sinpr_test$venta -
                                            df_GBM[[i]]$predict_gbm_sinpr)^2))
  GBM_rmse_spr <- c(GBM_rmse_spr, sqrt(mean((df_GBM[[i]]$sinpr_test$venta -
                                            df_GBM[[i]]$predict_gbm_sinpr)^2)))
  
  
  df_GBM[[i]]$gbm_pr <- gbm(venta ~.,
                               data = df_GBM[[i]]$pr,
                               distribution = "gaussian")
  df_GBM[[i]]$predict_gbm_pr <- predict(df_GBM[[i]]$gbm_pr,
                                           newdata = df_GBM[[i]]$pr_test)
  
    df_GBM[[i]]$rmse_gbm_sinpr <- sqrt(mean((df_GBM[[i]]$pr_test$venta -
                                            df_GBM[[i]]$predict_gbm_pr)^2))
    GBM_rmse_pr <- c(GBM_rmse_pr, sqrt(mean((df_GBM[[i]]$pr_test$venta -
                                            df_GBM[[i]]$predict_gbm_pr)^2)))
}
```

```{r}
factor_servicio <- 1.64 # Nivel de servicio del 95%

for (i in 1:length(unique(data_help$producto))) {
  
  ciclo_aprovisionamiento <- df_GBM[[i]]$diasLeadtime
  coste_unitario_pct <- df_GBM[[i]]$eurPrecioMedio
    # Calculamos el stock de seguridad sólo si se ha ajustado un modelo
  if (!is.null(df_GBM[[i]]$gbm_sinpr) | !is.null(df_GBM[[i]]$gbm_pr)) {
    # Calculamos el stock de seguridad para ambos modelos
    df_GBM[[i]]$stock_seguridad_sinpr <- factor_servicio * model_pr[[i]]$rmse_gbm_sinpr * sqrt(ciclo_aprovisionamiento)
    df_GBM[[i]]$stock_seguridad_pr <- factor_servicio * model_pr[[i]]$rmse_gbm_pr * sqrt(ciclo_aprovisionamiento)
  }
}

```




### FINAL? 
```{r, warning = FALSE}
# Ajuste del modelo GBM por producto
df_list_train <- split(df_train_gbm, df_train_gbm$producto)
df_list_test <- split(df_test_gbm, df_test_gbm$producto)
df_GBM <- vector(mode = "list", length = length(unique(df_train$producto)))
GBM_rmse_spr <- c()
GBM_rmse_pr <- c()

for (i in 1:length(unique(df_train$producto))) {
  start_time <- Sys.time()  # Captura el tiempo de inicio
  cat("Producto:", i, "\n")  # Muestra el producto actual
  df_GBM[[i]] <- list(
    sinpr = df_list_train[[i]] %>%
      select(dia, mes, any, bolOpen, udsVenta),
    pr = df_list_train[[i]] %>%
      select(dia, mes, any, bolOpen, udsVenta, promo_activated),
    sinpr_test = df_list_test[[i]] %>%
      select(dia, mes, any, bolOpen, udsVenta),
    pr_test = df_list_test[[i]] %>%
      select(dia, mes, any, bolOpen, udsVenta, promo_activated)
  )
  
  # Ajuste del modelo GBM sin promociones
  df_GBM[[i]]$gbm_sinpr <- gbm(
    udsVenta ~ .,
    data = df_GBM[[i]]$sinpr,
    distribution = "gaussian"
  )
  
  df_GBM[[i]]$predict_gbm_sinpr <- predict(
    df_GBM[[i]]$gbm_sinpr,
    newdata = df_GBM[[i]]$sinpr_test
  )
  
  df_GBM[[i]]$rmse_gbm_sinpr <- sqrt(mean((df_GBM[[i]]$sinpr_test$udsVenta - df_GBM[[i]]$predict_gbm_sinpr)^2))
  GBM_rmse_spr <- c(GBM_rmse_spr, df_GBM[[i]]$rmse_gbm_sinpr)
  
  # Ajuste del modelo GBM con promociones
  df_GBM[[i]]$gbm_pr <- gbm(
    udsVenta ~ .,
    data = df_GBM[[i]]$pr,
    distribution = "gaussian"
  )
  
  df_GBM[[i]]$predict_gbm_pr <- predict(
    df_GBM[[i]]$gbm_pr,
    newdata = df_GBM[[i]]$pr_test
  )
  
  df_GBM[[i]]$rmse_gbm_pr <- sqrt(mean((df_GBM[[i]]$pr_test$udsVenta - df_GBM[[i]]$predict_gbm_pr)^2))
  GBM_rmse_pr <- c(GBM_rmse_pr, df_GBM[[i]]$rmse_gbm_pr)
  
    end_time <- Sys.time()  # Captura el tiempo de finalización
  elapsed_time <- end_time - start_time  # Calcula el tiempo transcurrido
  cat("Tiempo transcurrido:", elapsed_time, "segundos\n\n")
}
```


### Ahora a ver exponential smoothing NO VA

```{r, eval = FALSE}
modelo_ets <- ets(df_prod_1_ventas_ts, x = df_prod_1_promo$promo_activated)

prediccion_ets <- forecast(modelo_ets, h = 30, x = df_prod_1_promo$promo_activated)
plot(prediccion_ets)
```


## Redes NEURONALES MIRAR MEJOR

### Nivell Global
```{r}
df_train_red <- df_train %>% 
  mutate(
    dia = day(Fecha),
    mes = month(Fecha),
    any = year(Fecha),
    dia_semana = wday(Fecha, label = FALSE)
  ) %>%
  select(-Fecha)

df_test_red <- df_test %>%
  mutate(
    dia = day(Fecha),
    mes = month(Fecha),
    any = year(Fecha),
    dia_semana = wday(Fecha, label = FALSE)
  ) %>%
  select(-Fecha)

# Instalar la biblioteca neuralnet si aún no está instalada

# Preparar los datos
train_data <- data.frame(
  x1 = df_train_red$dia,
  x2 = df_train_red$mes,
  x3 = df_train_red$any,
  x4 = df_train_red$producto,
  x5 = df_train_red$bolOpen,
  x6 = df_train_red$dia_semana,
  y = df_train_red$udsVenta
)

test_data <- data.frame(
  x1 = df_test_red$dia,
  x2 = df_test_red$mes,
  x3 = df_test_red$any,
  x4 = df_test_red$producto,
  x5 = df_test_red$bolOpen,
  x6 = df_test_red$dia_semana
)

# Entrenar la red neuronal
neuralnet_model <- neuralnet(
  y ~ x1 + x2 + x3 + x4 + x5 + x6,  # Fórmula de la red neuronal
  data = train_data,  # Datos de entrenamiento
  hidden = c(5, 3)  # Número y tamaño de las capas ocultas
)

# Realizar predicciones con la red neuronal
predictions <- compute(neuralnet_model, test_data)

# Acceder a las predicciones
predicted_values <- predictions$net.result
```

### A NIVEL PRODUCTO

### Provem a fer un gbm per producte

#### Arreglo datos
```{r, eval = FALSE}
df_list_train <- split(df_train_red, df_train$producto)
df_list_test <- split(df_test_red, df_test$producto)
df_RED <- vector(mode = "list", length = 1000)

# Preparamos los diferentes datasets
for (i in 1:length(unique(data_help$producto))) {
  df_list_train[[i]] <- as.list(df_list_train[[i]])
  df_RED[[i]]$sinpr <- data.frame(
  x1 = df_list_train[[i]]$dia,
  x2 = df_list_train[[i]]$mes,
  x3 = df_list_train[[i]]$any,
  x4 = df_list_train[[i]]$producto,
  x5 = df_list_train[[i]]$bolOpen,
  x6 = df_list_train[[i]]$dia_semana,
  y = df_list_train[[i]]$udsVenta
)
  df_RED[[i]]$pr <- data.frame(
  x1 = df_list_train[[i]]$dia,
  x2 = df_list_train[[i]]$mes,
  x3 = df_list_train[[i]]$any,
  x4 = df_list_train[[i]]$producto,
  x5 = df_list_train[[i]]$bolOpen,
  x6 = df_list_train[[i]]$dia_semana,
  x7 = df_list_train[[i]]$promo_activated
  y = df_list_train[[i]]$udsVenta
)
  df_RED[[i]]$diasEntrePedidos <- mean(df_list_train[[i]]$diasEntrePedido)
  df_RED[[i]]$diasLeadtime <- mean(df_list_train[[i]]$diasLeadtime)
  df_RED[[i]]$eurPrecioMedio <- mean(df_list_train[[i]]$eurPrecioMedio)
  df_RED[[i]]$Producto <- i
  df_list_test[[i]] <- as.list(df_list_test[[i]])
  df_RED[[i]]$sinpr_test <- data.frame(
  x1 = df_list_test[[i]]$dia,
  x2 = df_list_test[[i]]$mes,
  x3 = df_list_test[[i]]$any,
  x4 = df_list_test[[i]]$producto,
  x5 = df_list_test[[i]]$bolOpen,
  x6 = df_list_test[[i]]$dia_semana,
  y = df_list_test[[i]]$udsVenta
)
  df_RED[[i]]$pr_test <- data.frame(
  x1 = df_list_test[[i]]$dia,
  x2 = df_list_test[[i]]$mes,
  x3 = df_list_test[[i]]$any,
  x4 = df_list_test[[i]]$producto,
  x5 = df_list_test[[i]]$bolOpen,
  x6 = df_list_test[[i]]$dia_semana,
  x7 = df_list_test[[i]]$promo_activated
  y = df_list_test[[i]]$udsVenta
)
}
```

```{r, warning = FALSE, message = FALSE, eval = FALSE}
GBM_rmse_spr <- c()
GBM_rmse_pr <- c()
for (i in 1:length(unique(data_help$producto))) {
  df_GBM[[i]]$gbm_sinpr <- gbm(venta ~.,
                               data = df_GBM[[i]]$sinpr,
                               distribution = "gaussian")
  
  df_GBM[[i]]$predict_gbm_sinpr <- predict(df_GBM[[i]]$gbm_sinpr,
                                           newdata = df_GBM[[i]]$sinpr_test)
  df_GBM[[i]]$rmse_gbm_sinpr <- sqrt(mean((df_GBM[[i]]$sinpr_test$venta -
                                            df_GBM[[i]]$predict_gbm_sinpr)^2))
  GBM_rmse_spr <- c(GBM_rmse_spr, sqrt(mean((df_GBM[[i]]$sinpr_test$venta -
                                            df_GBM[[i]]$predict_gbm_sinpr)^2)))
  
  
  df_GBM[[i]]$gbm_pr <- gbm(venta ~.,
                               data = df_GBM[[i]]$pr,
                               distribution = "gaussian")
  df_GBM[[i]]$predict_gbm_pr <- predict(df_GBM[[i]]$gbm_pr,
                                           newdata = df_GBM[[i]]$pr_test)
  
    df_GBM[[i]]$rmse_gbm_sinpr <- sqrt(mean((df_GBM[[i]]$pr_test$venta -
                                            df_GBM[[i]]$predict_gbm_pr)^2))
    GBM_rmse_pr <- c(GBM_rmse_pr, sqrt(mean((df_GBM[[i]]$pr_test$venta -
                                            df_GBM[[i]]$predict_gbm_pr)^2)))
}
```

```{r}
factor_servicio <- 1.64 # Nivel de servicio del 95%

for (i in 1:length(unique(data_help$producto))) {
  
  ciclo_aprovisionamiento <- df_GBM[[i]]$diasLeadtime
  coste_unitario_pct <- df_GBM[[i]]$eurPrecioMedio
    # Calculamos el stock de seguridad sólo si se ha ajustado un modelo
  if (!is.null(df_GBM[[i]]$gbm_sinpr) | !is.null(df_GBM[[i]]$gbm_pr)) {
    # Calculamos el stock de seguridad para ambos modelos
    df_GBM[[i]]$stock_seguridad_sinpr <- factor_servicio * model_pr[[i]]$rmse_gbm_sinpr * sqrt(ciclo_aprovisionamiento)
    df_GBM[[i]]$stock_seguridad_pr <- factor_servicio * model_pr[[i]]$rmse_gbm_pr * sqrt(ciclo_aprovisionamiento)
  }
}

```

# MORDOR
https://github.com/manuparra/seriestemporales/blob/master/README.md

https://rpubs.com/AdSan-R/GBM